# Evaluation Summary - Run c13df0aa

## Dataset
- Total samples: 819
- Swarm valid samples: 1
- Big model valid samples: 0

## ROUGE Scores (F1)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| ROUGE-1 | 0.5333 | 0.0000 |
| ROUGE-2 | 0.1429 | 0.0000 |
| ROUGE-L | 0.4000 | 0.0000 |

## BERTScore

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Precision | 0.4535 | 0.0000 |
| Recall | 0.4242 | 0.0000 |
| F1 | 0.4398 | 0.0000 |

## Latency (seconds)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Mean | 150.05 | 0.00 |
| Median (p50) | 150.10 | 0.00 |
| p95 | 150.10 | 0.00 |

## Factuality

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Hallucination Rate | 100.00% | 100.00% |

## Consensus Metrics (Swarm Only)

| Metric | Value |
|--------|-------|
| Avg Consensus Similarity | 1.0000 |
| Outlier Detection Rate | 0.00% |
| Consensus Confidence | 0.0000 |

## Computational Statistics

| Metric | Value |
|--------|-------|
| Avg Input Length (words) | 95.5 |
| Avg Output Length (words) | 0.0 |

## Key Findings

1. **Quality (ROUGE-L)**: 0.4000
2. **Semantic Similarity (BERTScore)**: 0.4398
3. **Consensus Strength**: 1.0000
4. **Throughput**: 0.40 examples/minute

---

*Generated: 2025-12-05 02:15:25 UTC*
