# Evaluation Summary - Run c6f35987

## Dataset
- Total samples: 819
- Swarm valid samples: 353
- Big model valid samples: 0

## ROUGE Scores (F1)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| ROUGE-1 | 0.4431 | 0.0000 |
| ROUGE-2 | 0.1726 | 0.0000 |
| ROUGE-L | 0.3559 | 0.0000 |

## BERTScore

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Precision | 0.4471 | 0.0000 |
| Recall | 0.4637 | 0.0000 |
| F1 | 0.4551 | 0.0000 |

## Latency (seconds)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Mean | 81.16 | 0.00 |
| Median (p50) | 107.27 | 0.00 |
| p95 | 150.10 | 0.00 |

## Factuality

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Hallucination Rate | 79.60% | 100.00% |

## Consensus Metrics (Swarm Only)

| Metric | Value |
|--------|-------|
| Avg Consensus Similarity | 0.9353 |
| Outlier Detection Rate | 0.00% |
| Consensus Confidence | 0.0221 |

## Computational Statistics

| Metric | Value |
|--------|-------|
| Avg Input Length (words) | 95.5 |
| Avg Output Length (words) | 6.9 |

## Key Findings

1. **Quality (ROUGE-L)**: 0.3559
2. **Semantic Similarity (BERTScore)**: 0.4551
3. **Consensus Strength**: 0.9353
4. **Throughput**: 0.74 examples/minute

---

*Generated: 2025-12-03 16:06:12 UTC*
