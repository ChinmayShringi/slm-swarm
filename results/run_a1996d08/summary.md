# Evaluation Summary - Run a1996d08

## Dataset
- Total samples: 819
- Swarm valid samples: 0
- Big model valid samples: 0

## ROUGE Scores (F1)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| ROUGE-1 | 0.0000 | 0.0000 |
| ROUGE-2 | 0.0000 | 0.0000 |
| ROUGE-L | 0.0000 | 0.0000 |

## BERTScore

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Precision | 0.0000 | 0.0000 |
| Recall | 0.0000 | 0.0000 |
| F1 | 0.0000 | 0.0000 |

## Latency (seconds)

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Mean | 150.10 | 0.00 |
| Median (p50) | 150.10 | 0.00 |
| p95 | 150.10 | 0.00 |

## Factuality

| Metric | Swarm | Big Model |
|--------|-------|-----------|
| Hallucination Rate | 0.00% | 100.00% |

## Consensus Metrics (Swarm Only)

| Metric | Value |
|--------|-------|
| Avg Consensus Similarity | 0.0000 |
| Outlier Detection Rate | 0.00% |
| Consensus Confidence | 0.0000 |

## Computational Statistics

| Metric | Value |
|--------|-------|
| Avg Input Length (words) | 95.5 |
| Avg Output Length (words) | 0.0 |

## Key Findings

1. **Quality (ROUGE-L)**: 0.0000
2. **Semantic Similarity (BERTScore)**: 0.0000
3. **Consensus Strength**: 0.0000
4. **Throughput**: 0.40 examples/minute

---

*Generated: 2025-11-28 13:15:28 UTC*
