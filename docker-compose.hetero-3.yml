version: "3.8"

# Heterogeneous swarm: 3 workers (Qwen, Llama, Mistral)

services:
  worker_qwen:
    image: ollama/ollama:latest
    container_name: hetero3_worker_qwen
    volumes:
      - ./models/qwen:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - slm_net

  worker_llama:
    image: ollama/ollama:latest
    container_name: hetero3_worker_llama
    volumes:
      - ./models/llama:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - slm_net

  worker_mistral:
    image: ollama/ollama:latest
    container_name: hetero3_worker_mistral
    volumes:
      - ./models/mistral:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - slm_net

  coordinator:
    build: ./coordinator
    container_name: hetero3_coordinator
    environment:
      - WORKERS=["http://worker_qwen:11434","http://worker_llama:11434","http://worker_mistral:11434"]
      - MODELS=["qwen2.5:7b-instruct","llama3.1:8b","mistral:7b-instruct"]
      - WORKER_TEMPERATURES=[0.2,0.2,0.2]
      - CONSENSUS_METHOD=cosine
      - CONSENSUS_THRESHOLD=0.3
      - SWARM_TYPE=heterogeneous
      - BIGMODEL_URL=${BIGMODEL_URL:-}
      - BIGMODEL_MODEL=${BIGMODEL_MODEL:-}
      - BIGMODEL_TYPE=${BIGMODEL_TYPE:-openai}
      - BIGMODEL_API_KEY=${BIGMODEL_API_KEY:-}
    depends_on:
      - worker_qwen
      - worker_llama
      - worker_mistral
    ports:
      - "8003:8000"
    networks:
      - slm_net

  evaluator:
    build: ./evaluator
    container_name: hetero3_evaluator
    environment:
      - COORDINATOR_URL=http://coordinator:8000
      - DATASET_PATH=/app/dataset/samsum.jsonl
      - RESULTS_DIR=/app/results
      - ENABLE_BIG_MODEL=false
      - RUN_ID=${RUN_ID:-}
      - PYTHONUNBUFFERED=1
    volumes:
      - ./dataset:/app/dataset
      - ./results:/app/results
    depends_on:
      - coordinator
    networks:
      - slm_net
    profiles:
      - evaluation

networks:
  slm_net:
    driver: bridge

