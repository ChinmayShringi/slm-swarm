version: "3.8"

# Homogeneous swarm configuration: All workers use the same model
# This configuration tests consensus mechanism with identical models

services:
  worker_1:
    image: ollama/ollama:latest
    container_name: worker_1
    volumes:
      - ./models/homo_1:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - WORKER_TEMPERATURE=0.1
    command: ["/bin/sh", "-c", "ollama serve & sleep 10 && ollama pull ${HOMO_MODEL:-qwen2.5:7b-instruct} && tail -f /dev/null"]
    networks:
      - slm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5

  worker_2:
    image: ollama/ollama:latest
    container_name: worker_2
    volumes:
      - ./models/homo_2:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - WORKER_TEMPERATURE=0.3
    command: ["/bin/sh", "-c", "ollama serve & sleep 10 && ollama pull ${HOMO_MODEL:-qwen2.5:7b-instruct} && tail -f /dev/null"]
    networks:
      - slm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5

  worker_3:
    image: ollama/ollama:latest
    container_name: worker_3
    volumes:
      - ./models/homo_3:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - WORKER_TEMPERATURE=0.5
    command: ["/bin/sh", "-c", "ollama serve & sleep 10 && ollama pull ${HOMO_MODEL:-qwen2.5:7b-instruct} && tail -f /dev/null"]
    networks:
      - slm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5

  worker_4:
    image: ollama/ollama:latest
    container_name: worker_4
    volumes:
      - ./models/homo_4:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - WORKER_TEMPERATURE=0.7
    command: ["/bin/sh", "-c", "ollama serve & sleep 10 && ollama pull ${HOMO_MODEL:-qwen2.5:7b-instruct} && tail -f /dev/null"]
    networks:
      - slm_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5

  coordinator:
    build: ./coordinator
    container_name: coordinator_homo
    environment:
      - WORKERS=["http://worker_1:11434","http://worker_2:11434","http://worker_3:11434","http://worker_4:11434"]
      - MODELS=["${HOMO_MODEL:-qwen2.5:7b-instruct}","${HOMO_MODEL:-qwen2.5:7b-instruct}","${HOMO_MODEL:-qwen2.5:7b-instruct}","${HOMO_MODEL:-qwen2.5:7b-instruct}"]
      - WORKER_TEMPERATURES=[0.1,0.3,0.5,0.7]
      - JUDGE=
      - JUDGE_MODEL=
      - CONSENSUS_METHOD=${CONSENSUS_METHOD:-cosine}
      - CONSENSUS_THRESHOLD=${CONSENSUS_THRESHOLD:-0.3}
      - SWARM_TYPE=homogeneous
      - BIGMODEL_URL=${BIGMODEL_URL:-}
      - BIGMODEL_MODEL=${BIGMODEL_MODEL:-llama-3.1-70b-instruct}
      - BIGMODEL_TYPE=${BIGMODEL_TYPE:-openai}
      - BIGMODEL_API_KEY=${BIGMODEL_API_KEY:-}
      - GPT4_API_KEY=${GPT4_API_KEY:-}
      - CLAUDE_API_KEY=${CLAUDE_API_KEY:-}
    depends_on:
      worker_1:
        condition: service_healthy
      worker_2:
        condition: service_healthy
      worker_3:
        condition: service_healthy
      worker_4:
        condition: service_healthy
    ports:
      - "8000:8000"
    networks:
      - slm_net

  evaluator:
    build: ./evaluator
    container_name: evaluator_homo
    environment:
      - COORDINATOR_URL=http://coordinator_homo:8000
      - DATASET_PATH=${DATASET_PATH:-/app/dataset/messages.jsonl}
      - RESULTS_DIR=/app/results
      - ENABLE_BIG_MODEL=${ENABLE_BIG_MODEL:-true}
    volumes:
      - ./dataset:/app/dataset
      - ./results:/app/results
    depends_on:
      - coordinator
    networks:
      - slm_net
    profiles:
      - evaluation

networks:
  slm_net:
    driver: bridge

